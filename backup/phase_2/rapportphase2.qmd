---
title: "Rapport de projet - phase 2"
subtitle: "MTH8408"
author:
  - name: Oihan Cordelier, Oussama Mouhtal
    email: oihan.cordelier@polymtl.ca, oussama-2.mouhtal@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: article
    include-in-header:
      - text: |
            \usepackage{xspace}
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
engine: julia
---


```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate("projet_env_phase2")
Pkg.add("ADNLPModels")
Pkg.add("NLPModels")
Pkg.add("Krylov")
Pkg.add("LinearOperators")
Pkg.add("JSOSolvers")
Pkg.add("Plots")

Pkg.add("OptimizationProblems")  # collection + outils pour sélectionner les problèmes
include("subsolvers.jl")
# TODO: add CUTest
Pkg.add("SuiteSparseMatrixCollection")
Pkg.add("MatrixMarket")
using LinearAlgebra, NLPModels , ADNLPModels, Printf, Krylov, LinearOperators, SuiteSparseMatrixCollection, MatrixMarket 

using OptimizationProblems, OptimizationProblems.ADNLPProblems, JSOSolvers

using Plots
# gr(fmt = :png)
```


## Lien GitHub
Ce projet est accessible sur le dépot GitHub au lien suivant : [https://github.com/oihanc/mth8408_projet](https://github.com/oihanc/mth8408_projet).

# Contenu
Ce rapport est divisé en deux parties :

- Une première partie consacrée à la comparaison des performances de \texttt{LBFGS} (pour différentes tailles de mémoire) avec celles de \texttt{CG} et \texttt{DIOM}.\
- Une seconde partie portant sur la résolution de problèmes non linéaires.

# Retour sur la problématique
Le gradient conjugué est une méthode répandue pour résoudre les modèles quadratiques des algorithmes de région de confiance, cependant le CG souffre de perte d'orthogonalisation. Bourhis et al. (2019) ont démontré que CG revient à faire L-BFGS avec une mémoire de 1. L'idée est donc de valider si L-BFGS avec une mémoire supérieure à 1 aider l'efficacité des algorithmes de région de confiance. Bourhis et al. ont déjà démontré qu'augmenter la mémoire aide à résoudre les problèmes quadratiques avec moins d'itérations. De plus, une autre idée serait de tester un sous-solveur similaire à CG, cependant apportant des corrections pour l'orthogonalisation, telle que DIOM.

# Résolution de quadratique convexe

Cette partie consiste à comparer \texttt{CG} et \texttt{DIOM} à \texttt{LBFGS}. Le tableau ci-dessous récapitule l’ensemble des matrices SDP utilisées dans cette section.

\begin{center}
\begin{tabular}{lrrrr}
\toprule
Nom & n  & Condition number κ₂ \\
\midrule
494\_bus & 494 & 2.415×10\(^{6}\) \\
1138\_bus & 1 138 & 8.572×10\(^{6}\) \\
662\_bus & 662 &  7.941×10\(^{5}\) \\
bcsstk06 & 420 & 7.570×10\(^{6}\) \\
\bottomrule
\end{tabular}
\end{center}


```{julia}
"""
      get_mm()
Charge une matrice depuis la SuiteSparse Matrix Collection
"""
function get_mm(matrix_name)
  ssmc = ssmc_db()
  pb = ssmc_matrices(ssmc, "", matrix_name)
  fetch_ssmc(pb, format="MM")
  pb_path = fetch_ssmc(pb, format="MM")
  path_mtx = pb_path[1]
  A = MatrixMarket.mmread(joinpath(path_mtx, matrix_name * ".mtx"))
  #b = MatrixMarket.mmread(joinpath(path_mtx, matrix_name * "_b.mtx"))
  return A
end

"""
      memory(n, p)
Génère des indices équidistants pour mémoire limitée
"""
function memory(n, p)
    @assert 1 ≤ p ≤ n "p doit être entre 1 et n"
    indices = [floor(Int, i*n/p) for i in 1:p]
    indices = unique(sort(indices))  
    return indices
end

"""
      cg_lbfgs(A, b, name, listmem, atol, rtol)
Compare CG et L-BFGS pour différentes tailles de mémoire, et sauvegarde un graphique
"""
function cg_lbfgs(A, b, name, listmem, atol, rtol)
  

  (xcg,statscg) = cg(A, b; atol=atol, rtol=rtol,history=true)
  (xlbfgs,statslbfgs) = lbfgs(A, b; atol=atol, rtol=rtol, mem = 1) 
  gr()
  plot(statscg.residuals, label="‖r‖ cg ", lw=1, yaxis=:log, linestyle = :dot, xlabel="Itération", legend = :bottomleft)
  plot!(statslbfgs.residuals, label="‖r‖ lbfgs $(m = 1)", lw=1, linestyle = :dash)

  for mem in listmem
    (xlbfgs,statslbfgs) = lbfgs(A, b; atol=atol, rtol=rtol, mem = mem)  
    p = round(Int64, 100 * mem / n)
    if p > 0 && p < 100
      plot!(statslbfgs.residuals, label="‖r‖ lbfgs $(m = p)%", lw=1,linestyle = :dash)
    else
      plot!(statslbfgs.residuals, label="‖r‖ lbfgs $(m = p)%", lw=1,linestyle = :dot)
    end
    
  end
    
  savefig("CG_versus_lbfgs_$(name).pdf")
end

"""
    diom_lbfgs(A, b, name, listmem, atol, rtol)
Compare DIOM et L-BFGS pour différentes tailles de mémoire, et sauvegarde un graphique
"""
function diom_lbfgs(A, b, name, listmem, atol, rtol)
  
  (xlbfgs,statslbfgs) = lbfgs(A, b; atol=atol, rtol=rtol, mem = 2)  
  (xdiom,statsdiom) = diom(A, b; memory =2, atol=atol, rtol=rtol,history=true)
  gr()
  plot(statslbfgs.residuals, label="‖r‖ lbfgs $(m = 2)", lw=1,yaxis=:log, linestyle = :dash, xlabel="Itération",legend = :bottomright)
  plot!(statsdiom.residuals, label="‖r‖ diom $(m = 2)", linestyle = :dot, lw=1)
  for mem in listmem
    p = round(Int64, 100 * mem / n)
    if mem > 2 && p > 0
    (xlbfgs,statslbfgs) = lbfgs(A, b; atol=atol, rtol=rtol, mem = mem) 
    (xdiom,statsdiom) = diom(A, b; memory = mem,atol=atol, rtol=rtol,history=true)
    plot!(statslbfgs.residuals, label="‖r‖ lbfgs $(m = p)%", linestyle = :dash,lw=1)
    plot!(statsdiom.residuals, label="‖r‖ diom $(m = p)%", linestyle = :dot,lw=1)
    end
  end
  savefig("Diom_versus_lbfgs_$(name).pdf")
end

"""
      orthogonality_loss(A, b; maxiter, mem)
Calcule la perte d’orthogonalité associée aux directions L-BFGS pour plusieurs itérations

## Les tolérances dans lbfs sont ceux par défaut atol=1e-18, rtol=1e-18
"""

function orthogonality_loss(A, b; maxiter=10, mem=1)
    Loss = Float64[]
    for i in 2:maxiter
        (xlbfgs,statslbfgs) =  lbfgs(A, b; mem=mem, itmax = i)
        U = tril(statslbfgs.PAP, -1)                        # partie triangulaire inférieure stricte
        I_U = I + U         # U + I
        loss = norm(U)        # || (U + I)^(-1) * U ||_2
        push!(Loss, loss)              
    end        
    return Loss
end
```

## Comparaison CG à LBFGS

Dans cette partie, nous comparons la méthode du gradient conjugué (\texttt{CG}) à \texttt{LBFGS}, en faisant varier la taille de la mémoire utilisée. Nous traçons la norme du résidu en fonction des itérations. Voici les remarques principales :\

- \texttt{CG} génère des résidus très similaires à ceux de \texttt{LBFGS} avec une mémoire de taille 1. Dans les deux cas, la convergence n’est pas atteinte en $n$ itérations, en raison de la perte d’orthogonalité.\

- En augmentant la taille de la mémoire, la convergence de \texttt{LBFGS} s’améliore. Avec la mémoire complète, la solution est retrouvée en $n$ itérations (étant donné que \texttt{atol = rtol =} $10^{-9}$). Cependant, on observe que lorsque la norme du résidu devient très faible, \texttt{LBFGS} peine à continuer la réduction du résidu.

- La matrice utiliser est `494_bus`.

```{julia}
A = get_mm("494_bus")
n,n = size(A)
b = randn(eltype(A), n)
atol = 1e-9
rtol = 1e-9
p=4
listmem = memory(n, p)
cg_lbfgs(A, b, "494_bus", listmem,atol, rtol)
```

![](CG_versus_lbfgs_494_bus.pdf);

## Perte de conjugaison dans les directions de LBFGS

- Dans cette partie on vise à analyser la perte de conjugaison des directions générées. Soit $P_k \in \mathbb{R}^{n \times k}$ la matrice contenant les $k$ premières directions normalisées $d_i$. Si la famille $\{d_i\}$ est une base $A$-conjuguée, alors on devrait avoir :
$$
P_k^\top A P_k = I.
$$
Comme cette matrice est symétrique, on peut la décomposer en une somme :
$$
P_k^\top A P_k = U_k^\top + D_k + U_k.
$$
Une façon de mesurer la perte de conjugaison consiste donc à évaluer la norme de $U_k$, qui devrait être nulle si la conjugaison est parfaite. La figure ci dessous illustre l'volution de la norme de $U_k$ au cours des itérations pour différentes valeur du mémoire. La mtrice utiliser dans cette partie est `bcsstk06`.

- Il est important de souligner qu’une amélioration significative de la perte de conjugaison est obtenue  on augementant la mémoire de la matrice `lbfgs`. Meme on peut remarquer que dès une itération supérieur à la taille de la mémoire on perte la propriété de conjugaison des directions (ce n'est pas une généralisation).

```{julia}
A = get_mm("bcsstk06")
n,n = size(A)
b = randn(eltype(A), n)
p=5
listmem = memory(n, p)
Loss = orthogonality_loss(A, b; maxiter = n)
plot(Loss, label="$(m = 1)", lw=2, yaxis=:log, linestyle = :dot, xlabel="Itération", legend = :topleft)
for mem in listmem
  Loss = orthogonality_loss(A, b; maxiter = n, mem=mem)
  p = round(Int64, 100 * mem / n)
  if p > 0
    plot!(Loss, label="$(m = p)%", linestyle = :dot, lw=2)
  end
end
savefig("Loss_conjugacy.pdf")
```

![](Loss_conjugacy.pdf);


## Comparaison DIOM à LBFGS

- Cette partie est dédiée à la comparaison entre \texttt{DIOM} et \texttt{LBFGS}. La méthode \texttt{DIOM} est implémentée de manière à conserver en mémoire les vecteurs de la base générée au cours du processus de Krylov. En arithmétique exacte, cet algorithme est équivalent à la méthode du gradient conjugué (\texttt{CG}) pour les matrices SDP. De plus, en pratique, \texttt{DIOM} se comporte comme \texttt{CG} avec réorthogonalisation.

- On remarque que \texttt{LBFGS} et \texttt{DIOM} génèrent des résidus presque identiques au début. Toutefois, à partir d’un certain nombre d’itérations --- lorsque la norme du résidu devient très faible --- \texttt{DIOM} surpasse \texttt{LBFGS}, ce dernier n’étant plus capable de faire progresser la réduction du résidu.


```{julia}
A = get_mm("494_bus")
n,n = size(A)
b = randn(eltype(A), n)
p=2
listmem = memory(n, p)
diom_lbfgs(A, b, "494_bus", listmem,atol, rtol)
```

![](Diom_versus_lbfgs_494_bus.pdf);



```{julia}
A = get_mm("1138_bus")
n,n = size(A)
b = randn(eltype(A), n)
p=2
listmem = memory(n, p)
diom_lbfgs(A, b, "1138_bus", listmem,atol, rtol)
```

![](Diom_versus_lbfgs_1138_bus.pdf);





```{julia}
A = get_mm("662_bus")
n,n = size(A)
b = randn(eltype(A), n)
p=2
listmem = memory(n, p)
diom_lbfgs(A, b, "662_bus", listmem, atol, rtol)
```

![](Diom_versus_lbfgs_662_bus.pdf);


# Région de confiance

L'utilisation de CG et de L-BFGS est pour résoudre le sous-problème de minimisation du modèle quadratique. Nous nous sommes donc aussi intéressés à l'implémentation de l'algorithme de région de confiance. 
Pour le moment, nous avons reproduit l'algorithme tel que fournie dans le cahier du GERAD (Bourhis et al., 2019), cependant le code reste fortement inspiré du code `trunk` du module `JSOSolver.jl`. Un possible objectif pour la troisième phase de ce projet serait de directement modifier le solveur `trunk`. À des fins de comparaison, nous avons appelé notre solveur `TRSolver`. Afin de valider notre implémentation, nous l'avons comparé avec le solveur `trunk`ainsi que `Ipopt`. Notre solveur permet d'utiliser comme sous-solveur CG ou bien L-BFGS. Pour ce dernier, il est possible de varier le paramètre de mémoire. 


Pour la deuxième phase, nous avons eu comme objectifs de :


- Valider l'implémentation de `TRSolver` avec CG (notre implémentation) contre le solveur `trunk`. Ce sont essentiellement les mêmes algorithmes. Puisque `trunk` est déjà fortement optimisé, si `TRSolver` obtient des performances similaires, cela veut dire que notre implémentation de l'algorithme de région de confiance est efficace. 
- Comparer les performances de `TRSolver` avec CG et avec L-BFGS. L'idée est d'identifier si, à ce stade, nous avons des gains en efficacité avec L-BFGS. 
- Comparer les performances de `TRSolver` avec L-BFGS pour différents paramètres de mémoire. L'objectif est d'identifier comment le paramètre de mémoire impacte l'efficacité de l'algorithme.



Le code ci-dessous est celui de l'algorithme de région de confiance. Comme mentionné plus tôt, il est fortement inspiré de celui provenant de `JSOSolver`. Notamment, un effort particulier a été apporté pour le rendre compatible avec le module `SolverCore` et `SolverTools`. L'implémentation se base sur celle du cahier du GERAD (Bourhis et al., 2019). Une différence notable est la modification dynamique de la tolérance relative du sous-solveur. Celle-ci suit l'implémentation dans `JSOSolver` afin de s'assurer qu'elle ne soit jamais plus stricte que le solveur de région de confiance.


Voici les modifications les plus importantes par rapport à la phase 1 : 


- Compatibilité avec les modules `SolverTools` et `SolverBenchmark` pour faciliter les comparaisons. On peut noter particulièrement l'utilisation de la structure `GenericExecutionStats`, l'ajout du temps écoulé et du statut de convergence.
- Utilisation de l'opérateur hessien du NLPModel au lieu de la matrice hessienne pour gagner en efficacité. 
- Le réglage dynamique de la tolérance relative du sous-solveur.


{{< pagebreak >}}


```julia
{{< include TRSolver.jl >}}
```


Pour comparer les performances des solveurs, nous utilisons tous les problèmes non contraints de dimensions 100 dans le module `OptimizationProblems`. Les profiles de performance sont faits avec le module `OptimizationBenchmark`. Ceci permet d'illustrer la portion de problème résolu par les algorithmes en fonction d'un ratio d'itération ou de temps. 


Un problème est dit $\tau$-résolu si la condition suivante est rencontrée : 


\begin{align*}
\frac{f^i - f^0}{f^* - f^0} \geq (1 - \tau)
\end{align*}


Les algorithmes suivants sont testés :


- `trunk` : région de confiance avec CG (implémentation provenant de `JSOSolver`)
- `trSolver_cg` : région de confiance avec CG 
- `trsolver_lbfgs` : région de confiance avec L_BFGS. Le nombre associé indique la mémoire utilisée.
- `Ipopt` : optimiseur à points intérieurs


Le script ci-dessous permet de lancer les différents solveurs sur les problèmes tests. Les données sont sauvegardées et peuvent être réutilisées plus tard sans relancer les tests.


{{< pagebreak >}}


```julia
{{< include benchmark_solvers.jl >}}
```


Nous proposons 3 profiles de performance en fonction de plusieurs critères, soit le nombre d'itérations, le nombre d'évaluations de la fonction objective et le temps écoulé. Nous proposons ces 3 critères puisque certains algorithmes peuvent prendre moins d'itérations que d'autres, cependant chaque itération est plus longue à évaluer. 


![Profile de performance en fonction du nombre d'itérations](performance_profile_iter.png){width=80%  fig-align="center"}


![Profile de performance en fonction du nombre d'évaluations de la fonction objective](performance_profile_neval.png){width=80% fig-align="center"}


![Profile de performance en fonction du temps écoulé](performance_profile_time.png){width=80% fig-align="center"}



### Classement des algorithmes
À la lumière des résultats obtenus, nous pouvons déjà tirer quelques conclusions sur notre implémentation de l'algorithme de région de confiance. Le profile de performance en fonction du temps illustre que : 


- `trunk` est l'implémentation qui résout le plus de problèmes rapidement. 
- `TRSolver` performe initialement moins bien, mais rapidement rapidement `trunk`. 
- `TRSolver` avec L-BFGS performe nettement moins bien. 
- `Ipopt` est l'algorithme le moins efficace en termes de temps.


### Influence des paramètres de L-BFGS


![Profile de performance en fonction du temps écoulé pour les sous-solveurs L-BFGS](performance_profile_time_lbfgs.png){width=80% fig-align="center"}


Le profile de performance ci-haut montre qu'il y a peu de gain en efficacité lorsque la mémoire est augmentée. Cependant, on peut tout de même noter que lorsque la mémoire est réglée à 10 et sans mise à l'échelle, l'optimiseur de région de confiance performe légèrement mieux qu'avec les autres paramètres de mémoire. Il reste donc à voir si avec une implémentation plus efficace de L-BFGS, nous pouvons obtenir de meilleur résultat que `TRSolver` avec CG. De plus, il serait intéressant de voir s'il est possible d'aller chercher des gains supplémentaires en augmentant davantage la mémoire.


## Difficultés rencontrées


- Pour l'implémentation du sous-solveur L-BFGS, nous voulions initialement modifier le code de `trunk`. À la place nous avons jugé qu'il était plus facile de reproduit l'algorithme de région de confiance pour faire des tests initiaux avec L-BFGS. Son utilisation reste compatible avec `SolverCore`.



## Résumé de ce qui a été accompli
- Comparaison de la résolution des sous-problèmes convexes avec CG, L-BFGS et DIOM.
- Implémentation de l'algorithme de région de confiance revue
- Comparaison des divers solveurs avec `SolverBenchmark`
- Comparaison de l'effet de la mémoire et de la mise à l'échelle avec le sous-solveur L-BFGS.



## Étapes à terminer
- Implémenter dans \texttt{Krylov.jl} une version de \texttt{DIOM} adaptée à la résolution de sous-problèmes de région de confiance.
- Analyser la stagnation de \texttt{LBFGS} lorsque la norme du résidu devient très faible (inférieure à $10^{-6}$).
- Finaliser une implémentation opérationnelle de la méthode \texttt{LBFGS}.
- Ajouter DIOM comme sous-solveur possible dans l'algorithme de région de confiance `TRSolver`.
- Comparer les solveurs sur des problèmes de plus grandes dimensions (au minimum 1000 variables).
- *Si les prochains résultats avec L-BFGS sont concluants, il serait intéressant de modifier la fonction `trunk` pour permettre l'utilisation de L-BFGS*.


## Annexes

Code L-BFGS avec région de confiance(non optimisé, implémentation à revoir)
```julia
{{< include subsolvers.jl >}}
```

